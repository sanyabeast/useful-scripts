This Python script, `hashnamer.py`, is designed to rename files within a specified directory based on their content hashes. It offers several customization options for controlling the renaming process and handling duplicates.  

Here's a breakdown of its functionality:

**1. Usage:**
   - The script accepts various command-line arguments to configure its behavior. 
   - **`<directory_path>`**: The directory containing the files you want to rename.
   - **`[delete_dupes]`**: (Optional) Set to `true` if you want to remove duplicate files after renaming.
   - **`[extensions]`**: (Optional) A comma-separated list of file extensions to process. If omitted, all files are processed.
   - **`[method]`**: (Optional) The hashing algorithm to use: 'md5', 'sha256', or 'sha512'. Defaults to 'md5'.
   - **`[global_dupes]`**: (Optional) Set to `true` if you want to track duplicate files globally across all subdirectories. Otherwise, duplicate tracking is done within each subdirectory.
   - **`[trim_name]`**: (Optional)  The length to trim the hash for the new file name. Defaults to 64.

**2. File Hash Generation:**
   - The script uses `hashlib` to generate hashes (MD5, SHA-256, or SHA-512) based on the content of each file. This ensures unique names even if files have identical names but different contents.

**3. Duplicate Handling:**

   - If `delete_dupes` is set to `true`, the script removes duplicate files identified by their hashes. 
   - If `delete_dupes` is `false`, it skips renaming duplicate files and prints a message indicating they were skipped.

**4. Renaming Process:**
   - The script iterates through each file in the specified directory (and its subdirectories if `global_dupes` is false).
   - If a hash collision occurs (two files have the same hash), it skips renaming the second file to avoid overwriting. 

**5. Output:**

   - After processing, the script prints statistics:
      - Total files renamed.
      - Total files skipped.
      - Total duplicate files removed.
      - Total duplicate files skipped.

