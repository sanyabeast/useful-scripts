# PyTorch Model Precision Converter

This script converts the precision of a PyTorch model saved in SafeTensors format (`.safetensors`) to a specified precision (FP16, FP32, or FP8). This can be useful for reducing memory usage or accelerating inference on devices with limited resources.


**Usage:**

```bash
python converter.py <input_safetensors_path> <output_safetensors_path> <precision>
```

* **`<input_safetensors_path>`**: Path to the input SafeTensors file containing your PyTorch model.
* **`<output_safetensors_path>`**: Path where you want to save the converted model (e.g., `model_fp16.safetensors`).
* **`<precision>`**: The desired output precision (one of: "fp16", "fp32", or "fp8").

**Example:**

```bash
python converter.py my_model.safetensors my_model_fp16.safetensors fp16
```



This will convert the model in `my_model.safetensors` to FP16 precision and save it as `my_model_fp16.safetensors`.




**How it Works:**

1. **Load Model:** The script loads the PyTorch model from the input SafeTensors file using the `load_file` function from the `safetensors` library.
2. **Convert Precision:** It iterates through each tensor in the loaded model and converts its data type to the specified precision (`torch.float16`, `torch.float32`, or `torch.float8_e4m3fn` for FP8). 
3. **Save Converted Model:** The script saves the converted tensors back into a new SafeTensors file at the specified output path.



**Requirements:**

*  Python 3+
*  PyTorch (`pip install torch`)
*   `safetensors` library (`pip install safetensors`)